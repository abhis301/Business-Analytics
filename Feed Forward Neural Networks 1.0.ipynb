{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from __future__ import division\n",
    "%matplotlib inline\n",
    "np.random.seed(0)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneOut\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "N = 100 # number of points per class\n",
    "D = 2 # dimensionality\n",
    "K = 3 # number of classes\n",
    "X = np.zeros((N*K,D))\n",
    "y = np.zeros(N*K, dtype='uint8')\n",
    "for j in xrange(K):\n",
    "    ix = range(N*j,N*(j+1))\n",
    "    r = np.linspace(0.0,1,N) # radius\n",
    "    t = np.linspace(j*4,(j+1)*4,N) + np.random.randn(N)*0.2 # theta\n",
    "    X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
    "    y[ix] = j\n",
    "\n",
    "pickle.dump(X,open('dataX.pickle','wb'))\n",
    "pickle.dump(y,open('dataY.pickle','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into test and train (20%:80%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240L, 2L)\n",
      "(60L, 2L)\n",
      "(240L,)\n",
      "(60L,)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print X_test.shape\n",
    "print y_train.shape\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a linear classifer assuming the multiclass logistic loss and an L2 regularization for the weights only. Report the prediction accuracy on the training data and the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x934a2e8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhcAAAFkCAYAAACThxm6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJxdmZmaWlJMLMzMzS8rJhZmZmSX1P3M6SSzbar3/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26d27b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Define some local varaibles\n",
    "D = X.shape[1] #Number of features\n",
    "K = max(y)+1 #Number of classes assuming class index starts from 0\n",
    "\n",
    "#Plot the data\n",
    "fig = plt.figure()\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0: loss 1.098749\n",
      "iteration 1000: loss 0.329071\n",
      "iteration 2000: loss 0.265955\n",
      "iteration 3000: loss 0.251593\n",
      "iteration 4000: loss 0.250070\n",
      "iteration 5000: loss 0.249420\n",
      "iteration 6000: loss 0.248994\n",
      "iteration 7000: loss 0.248722\n",
      "iteration 8000: loss 0.248543\n",
      "iteration 9000: loss 0.248410\n",
      "train accuracy: 0.98\n",
      "test accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Feedforward neural net model\n",
    "\n",
    "\n",
    "# Weights initialization\n",
    "h = 100 # size of hidden layer\n",
    "W1 = 0.01 * np.random.randn(D,h)\n",
    "b1 = np.zeros((1,h))\n",
    "W2 = 0.01 * np.random.randn(h,K)\n",
    "b2 = np.zeros((1,K))\n",
    "\n",
    "# Initializing values from hyperparameter\n",
    "reg = 1e-3 # regularization strength\n",
    "\n",
    "#batch SGD using manual backprop\n",
    "\n",
    "#Batch size is equal to number of examples\n",
    "num_examples = X_train.shape[0]\n",
    "\n",
    "#Initial value for the Gradient Descent Parameter\n",
    "step_size = 1e-0 #Also called learning rate\n",
    "\n",
    "# gradient descent loop\n",
    "for i in xrange(10000):\n",
    "    # evaluate class scores, [N x K]\n",
    "    hidden_layer = np.maximum(0, np.dot(X_train, W1) + b1) # note, ReLU activation\n",
    "    scores = np.dot(hidden_layer, W2) + b2\n",
    "    \n",
    "    # compute the class probabilities\n",
    "    exp_scores = np.exp(scores)\n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # [N x K]\n",
    "    \n",
    "    # compute the loss: average cross-entropy loss and regularization\n",
    "    corect_logprobs = -np.log(probs[range(num_examples),y_train])\n",
    "    data_loss = np.sum(corect_logprobs)/num_examples\n",
    "    reg_loss = 0.5*reg*np.sum(W1*W1) + 0.5*reg*np.sum(W2*W2)\n",
    "    loss = data_loss + reg_loss\n",
    "    if i % 1000 == 0:\n",
    "        print \"iteration %d: loss %f\" % (i, loss)\n",
    "  \n",
    "    # compute the gradient on scores\n",
    "    dscores = probs\n",
    "    dscores[range(num_examples),y_train] -= 1\n",
    "    dscores /= num_examples\n",
    "  \n",
    "    # backpropate the gradient to the parameters\n",
    "    \n",
    "    # first backprop into parameters W2 and b2\n",
    "    dW2 = np.dot(hidden_layer.T, dscores)\n",
    "    db2 = np.sum(dscores, axis=0, keepdims=True)\n",
    "    \n",
    "    # next backprop into hidden layer\n",
    "    dhidden = np.dot(dscores, W2.T)\n",
    "    \n",
    "    # backprop the ReLU non-linearity\n",
    "    dhidden[hidden_layer <= 0] = 0\n",
    "    \n",
    "    # finally into W1,b1\n",
    "    dW1 = np.dot(X_train.T, dhidden)\n",
    "    db1 = np.sum(dhidden, axis=0, keepdims=True)\n",
    "  \n",
    "    # add regularization gradient contribution\n",
    "    dW2 += reg * W2\n",
    "    dW1 += reg * W1\n",
    "  \n",
    "    # perform a parameter update\n",
    "    W1 += -step_size * dW1\n",
    "    b1 += -step_size * db1\n",
    "    W2 += -step_size * dW2\n",
    "    b2 += -step_size * db2\n",
    "\n",
    "    \n",
    "# Post-training: evaluate t set accuracy\n",
    "hidden_layer = np.maximum(0, np.dot(X_train, W1) + b1)\n",
    "scores = np.dot(hidden_layer, W2) + b2\n",
    "predicted_class = np.argmax(scores, axis=1)\n",
    "print 'train accuracy: %.2f' % (np.mean(predicted_class == y_train))\n",
    "\n",
    "# Post-training: evaluate test set accuracy\n",
    "hidden_layer = np.maximum(0, np.dot(X_test, W1) + b1)\n",
    "scores = np.dot(hidden_layer, W2) + b2\n",
    "predicted_class = np.argmax(scores, axis=1)\n",
    "print 'test accuracy: %.2f' % (np.mean(predicted_class == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduce a cross validation scheme "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=10, random_state=None, shuffle=True)\n",
      "\n",
      " 1 fold\n",
      "(216L, 2L)\n",
      "(24L, 2L)\n",
      "iteration 0: loss 0.252623\n",
      "iteration 1000: loss 0.250344\n",
      "iteration 2000: loss 0.250054\n",
      "iteration 3000: loss 0.249933\n",
      "iteration 4000: loss 0.249852\n",
      "iteration 5000: loss 0.249795\n",
      "iteration 6000: loss 0.249756\n",
      "iteration 7000: loss 0.249712\n",
      "iteration 8000: loss 0.249676\n",
      "iteration 9000: loss 0.249636\n",
      "iteration 10000: loss 0.249623\n",
      "iteration 11000: loss 0.249591\n",
      "iteration 12000: loss 0.249569\n",
      "iteration 13000: loss 0.249549\n",
      "iteration 14000: loss 0.249532\n",
      "train accuracy: 0.99\n",
      "validation accuracy: 0.92\n",
      "\n",
      " 2 fold\n",
      "(216L, 2L)\n",
      "(24L, 2L)\n",
      "iteration 0: loss 0.262948\n",
      "iteration 1000: loss 0.253362\n",
      "iteration 2000: loss 0.253221\n",
      "iteration 3000: loss 0.253163\n",
      "iteration 4000: loss 0.253124\n",
      "iteration 5000: loss 0.253095\n",
      "iteration 6000: loss 0.253083\n",
      "iteration 7000: loss 0.253074\n",
      "iteration 8000: loss 0.253075\n",
      "iteration 9000: loss 0.253061\n",
      "iteration 10000: loss 0.253056\n",
      "iteration 11000: loss 0.253053\n",
      "iteration 12000: loss 0.253045\n",
      "iteration 13000: loss 0.253046\n",
      "iteration 14000: loss 0.253036\n",
      "train accuracy: 0.99\n",
      "validation accuracy: 1.00\n",
      "\n",
      " 3 fold\n",
      "(216L, 2L)\n",
      "(24L, 2L)\n",
      "iteration 0: loss 0.245270\n",
      "iteration 1000: loss 0.244312\n",
      "iteration 2000: loss 0.244291\n",
      "iteration 3000: loss 0.244279\n",
      "iteration 4000: loss 0.244277\n",
      "iteration 5000: loss 0.244278\n",
      "iteration 6000: loss 0.244268\n",
      "iteration 7000: loss 0.244269\n",
      "iteration 8000: loss 0.244262\n",
      "iteration 9000: loss 0.244267\n",
      "iteration 10000: loss 0.244266\n",
      "iteration 11000: loss 0.244259\n",
      "iteration 12000: loss 0.244256\n",
      "iteration 13000: loss 0.244261\n",
      "iteration 14000: loss 0.244252\n",
      "train accuracy: 0.98\n",
      "validation accuracy: 1.00\n",
      "\n",
      " 4 fold\n",
      "(216L, 2L)\n",
      "(24L, 2L)\n",
      "iteration 0: loss 0.252460\n",
      "iteration 1000: loss 0.251507\n",
      "iteration 2000: loss 0.251479\n",
      "iteration 3000: loss 0.251468\n",
      "iteration 4000: loss 0.251465\n",
      "iteration 5000: loss 0.251464\n",
      "iteration 6000: loss 0.251457\n",
      "iteration 7000: loss 0.251459\n",
      "iteration 8000: loss 0.251452\n",
      "iteration 9000: loss 0.251454\n",
      "iteration 10000: loss 0.251454\n",
      "iteration 11000: loss 0.251452\n",
      "iteration 12000: loss 0.251458\n",
      "iteration 13000: loss 0.251452\n",
      "iteration 14000: loss 0.251446\n",
      "train accuracy: 0.99\n",
      "validation accuracy: 1.00\n",
      "\n",
      " 5 fold\n",
      "(216L, 2L)\n",
      "(24L, 2L)\n",
      "iteration 0: loss 0.252665\n",
      "iteration 1000: loss 0.251897\n",
      "iteration 2000: loss 0.251887\n",
      "iteration 3000: loss 0.251872\n",
      "iteration 4000: loss 0.251871\n",
      "iteration 5000: loss 0.251863\n",
      "iteration 6000: loss 0.251863\n",
      "iteration 7000: loss 0.251863\n",
      "iteration 8000: loss 0.251857\n",
      "iteration 9000: loss 0.251860\n",
      "iteration 10000: loss 0.251860\n",
      "iteration 11000: loss 0.251849\n",
      "iteration 12000: loss 0.251853\n",
      "iteration 13000: loss 0.251854\n",
      "iteration 14000: loss 0.251848\n",
      "train accuracy: 0.99\n",
      "validation accuracy: 1.00\n",
      "\n",
      " 6 fold\n",
      "(216L, 2L)\n",
      "(24L, 2L)\n",
      "iteration 0: loss 0.241666\n",
      "iteration 1000: loss 0.239327\n",
      "iteration 2000: loss 0.239241\n",
      "iteration 3000: loss 0.239221\n",
      "iteration 4000: loss 0.239210\n",
      "iteration 5000: loss 0.239208\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10,random_state = None,shuffle = True)\n",
    "kf.get_n_splits(X_train)\n",
    "print(kf)  \n",
    "validation_accuracy = []\n",
    "cnt=0\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    cnt=cnt+1\n",
    "    print \"\\n {} fold\".format(cnt)\n",
    "    \n",
    "    X_train1, X_test1 = X_train[train_index], X_train[test_index]\n",
    "    y_train1, y_test1 = y_train[train_index], y_train[test_index]\n",
    "    print X_train1.shape\n",
    "    print X_test1.shape\n",
    "    num_examples_cv = len(y_train1)\n",
    "    \n",
    "    for i in xrange(15000):\n",
    "        # evaluate class scores, [N x K]\n",
    "        hidden_layer = np.maximum(0, np.dot(X_train1, W1) + b1) # note, ReLU activation\n",
    "        scores = np.dot(hidden_layer, W2) + b2\n",
    "\n",
    "        # compute the class probabilities\n",
    "        exp_scores = np.exp(scores)\n",
    "        probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # [N x K]\n",
    "\n",
    "        # compute the loss: average cross-entropy loss and regularization\n",
    "        corect_logprobs = -np.log(probs[range(num_examples_cv),y_train1])\n",
    "        data_loss = np.sum(corect_logprobs)/num_examples_cv\n",
    "        reg_loss = 0.5*reg*np.sum(W1*W1) + 0.5*reg*np.sum(W2*W2)\n",
    "        loss = data_loss + reg_loss\n",
    "        if i % 1000 == 0:\n",
    "            print \"iteration %d: loss %f\" % (i, loss)\n",
    "\n",
    "        # compute the gradient on scores\n",
    "        dscores = probs\n",
    "        dscores[range(num_examples_cv),y_train1] -= 1\n",
    "        dscores /= num_examples_cv\n",
    "\n",
    "        # backpropate the gradient to the parameters\n",
    "\n",
    "        # first backprop into parameters W2 and b2\n",
    "        dW2 = np.dot(hidden_layer.T, dscores)\n",
    "        db2 = np.sum(dscores, axis=0, keepdims=True)\n",
    "\n",
    "        # next backprop into hidden layer\n",
    "        dhidden = np.dot(dscores, W2.T)\n",
    "\n",
    "        # backprop the ReLU non-linearity\n",
    "        dhidden[hidden_layer <= 0] = 0\n",
    "\n",
    "        # finally into W1,b1\n",
    "        dW1 = np.dot(X_train1.T, dhidden)\n",
    "        db1 = np.sum(dhidden, axis=0, keepdims=True)\n",
    "\n",
    "        # add regularization gradient contribution\n",
    "        dW2 += reg * W2\n",
    "        dW1 += reg * W1\n",
    "\n",
    "        # perform a parameter update\n",
    "        W1 += -step_size * dW1\n",
    "        b1 += -step_size * db1\n",
    "        W2 += -step_size * dW2\n",
    "        b2 += -step_size * db2\n",
    "        \n",
    "        \n",
    "    # Post-training: evaluate training set accuracy\n",
    "    hidden_layer = np.maximum(0, np.dot(X_train1, W1) + b1)\n",
    "    scores = np.dot(hidden_layer, W2) + b2\n",
    "    predicted_class = np.argmax(scores, axis=1)\n",
    "    print 'train accuracy: %.2f' % (np.mean(predicted_class == y_train1))\n",
    "    \n",
    "    # Post-training: evaluate validation set accuracy\n",
    "    hidden_layer = np.maximum(0, np.dot(X_test1, W1) + b1)\n",
    "    scores = np.dot(hidden_layer, W2) + b2\n",
    "    predicted_class = np.argmax(scores, axis=1)\n",
    "    print 'validation accuracy: %.2f' % (np.mean(predicted_class == y_test1))\n",
    "    \n",
    "    validation_accuracy.append(np.mean(predicted_class == y_test1))\n",
    "    \n",
    "    W1_new = W1\n",
    "    W2_new = W2\n",
    "    b1_new = b1\n",
    "    b2_new = b2\n",
    "    \n",
    "print \"Mean of validation accuracy is {}\".format(np.mean(validation_accuracy))\n",
    "# Post-validation: evaluate test set accuracy\n",
    "\n",
    "hidden_layer = np.maximum(0, np.dot(X_test, W1_new) + b1_new)\n",
    "scores = np.dot(hidden_layer, W2_new) + b2_new\n",
    "predicted_class = np.argmax(scores, axis=1)\n",
    "print 'test accuracy: %.2f' % (np.mean(predicted_class == y_test))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sensitivity of the model's performance to different learning rates and the number of gradient descent iterations via suitable plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Weights initialization\n",
    "h = 100 # size of hidden layer\n",
    "W1 = 0.01 * np.random.randn(D,h)\n",
    "b1 = np.zeros((1,h))\n",
    "W2 = 0.01 * np.random.randn(h,K)\n",
    "b2 = np.zeros((1,K))\n",
    "\n",
    "# Initializing values from hyperparameter\n",
    "reg = 1e-3 # regularization strength\n",
    "\n",
    "#batch SGD using manual backprop\n",
    "\n",
    "#Batch size is equal to number of examples\n",
    "num_examples = X_train.shape[0]\n",
    "\n",
    "#Initial value for the Gradient Descent Parameter\n",
    "# step_size = 1e-0 #Also called learning rate\n",
    "\n",
    "step_size = [0.000001,0.00001,0.0001,0.001,0.01,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,1.25,1.5,1.75,2.0,2.25,2.5,2.75,3.0,3.25,3.5]\n",
    "d1 = {}\n",
    "d2 = {}\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "for a in step_size:\n",
    "    \n",
    "    # gradient descent loop\n",
    "    for i in xrange(10000):\n",
    "        # evaluate class scores, [N x K]\n",
    "        hidden_layer = np.maximum(0, np.dot(X_train, W1) + b1) # note, ReLU activation\n",
    "        scores = np.dot(hidden_layer, W2) + b2\n",
    "\n",
    "        # compute the class probabilities\n",
    "        exp_scores = np.exp(scores)\n",
    "        probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # [N x K]\n",
    "\n",
    "        # compute the loss: average cross-entropy loss and regularization\n",
    "        corect_logprobs = -np.log(probs[range(num_examples),y_train])\n",
    "        data_loss = np.sum(corect_logprobs)/num_examples\n",
    "        reg_loss = 0.5*reg*np.sum(W1*W1) + 0.5*reg*np.sum(W2*W2)\n",
    "        loss = data_loss + reg_loss\n",
    "        if i % 1000 == 0:\n",
    "            print \"iteration %d: loss %f\" % (i, loss)\n",
    "\n",
    "        # compute the gradient on scores\n",
    "        dscores = probs\n",
    "        dscores[range(num_examples),y_train] -= 1\n",
    "        dscores /= num_examples\n",
    "\n",
    "        # backpropate the gradient to the parameters\n",
    "\n",
    "        # first backprop into parameters W2 and b2\n",
    "        dW2 = np.dot(hidden_layer.T, dscores)\n",
    "        db2 = np.sum(dscores, axis=0, keepdims=True)\n",
    "\n",
    "        # next backprop into hidden layer\n",
    "        dhidden = np.dot(dscores, W2.T)\n",
    "\n",
    "        # backprop the ReLU non-linearity\n",
    "        dhidden[hidden_layer <= 0] = 0\n",
    "\n",
    "        # finally into W1,b1\n",
    "        dW1 = np.dot(X_train.T, dhidden)\n",
    "        db1 = np.sum(dhidden, axis=0, keepdims=True)\n",
    "\n",
    "        # add regularization gradient contribution\n",
    "        dW2 += reg * W2\n",
    "        dW1 += reg * W1\n",
    "\n",
    "        # perform a parameter update\n",
    "        W1 += - a * dW1\n",
    "        b1 += - a * db1\n",
    "        W2 += - a * dW2\n",
    "        b2 += - a * db2\n",
    "\n",
    "\n",
    "    # Post-training: evaluate training set accuracy\n",
    "    hidden_layer = np.maximum(0, np.dot(X_train, W1) + b1)\n",
    "    scores = np.dot(hidden_layer, W2) + b2\n",
    "    predicted_class = np.argmax(scores, axis=1)\n",
    "    print \"Step size is {}\".format(a)\n",
    "    print 'train accuracy: %.2f' % (np.mean(predicted_class == y_train))\n",
    "    d1[a] = np.mean((predicted_class == y_train))\n",
    "    \n",
    "    train_accuracy.append(np.mean(predicted_class == y_train))\n",
    "    \n",
    "\n",
    "    # Post-training: evaluate test set accuracy\n",
    "    hidden_layer = np.maximum(0, np.dot(X_test, W1) + b1)\n",
    "    scores = np.dot(hidden_layer, W2) + b2\n",
    "    predicted_class = np.argmax(scores, axis=1)\n",
    "    print \"Step size is {}\".format(a)\n",
    "\n",
    "    print 'test accuracy: %.2f' % (np.mean(predicted_class == y_test))\n",
    "    d2[a] = np.mean((predicted_class == y_test))\n",
    "\n",
    "    test_accuracy.append(np.mean(predicted_class == y_test))\n",
    "\n",
    "print d1\n",
    "print d2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2,2,figsize = (15,15))\n",
    "\n",
    "\n",
    "for key,value in d1.items():\n",
    "    ax[0,0].semilogx(key,value,'r',marker = 'o',linestyle = '')\n",
    "\n",
    "for key,value in d2.items():\n",
    "    ax[0,1].semilogx(key,value,'g',marker = 'o',linestyle = '')\n",
    "\n",
    "ax[0,0].set_xlabel(\"Log of Learning Rate\")\n",
    "ax[0,0].set_ylabel(\"Training Accuracies\")\n",
    "ax[0,1].set_xlabel(\"Log of Learning Rate\")\n",
    "ax[0,1].set_ylabel(\"Test Accuracies\")\n",
    "\n",
    "\n",
    "L=[[key,value] for key,value in d1.items()]\n",
    "L.sort(key= lambda x: x[0])\n",
    "L=np.array(L)\n",
    "\n",
    "ax[1,0].semilogx(L[:,0],L[:,1],'r',marker = 'o',linestyle = '-')\n",
    "\n",
    "L=[[key,value] for key,value in d2.items()]\n",
    "L.sort(key= lambda x: x[0])\n",
    "L=np.array(L)\n",
    "\n",
    "ax[1,1].semilogx(L[:,0],L[:,1],'g',marker = 'o',linestyle = '-')\n",
    "\n",
    "ax[1,0].set_xlabel(\"Log of Learning Rate\")\n",
    "ax[1,0].set_ylabel(\"Training Accuracies\")\n",
    "ax[1,1].set_xlabel(\"Log of Learning Rate\")\n",
    "ax[1,1].set_ylabel(\"Test Accuracies\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Weights initialization\n",
    "h = 100 # size of hidden layer\n",
    "W1 = 0.01 * np.random.randn(D,h)\n",
    "b1 = np.zeros((1,h))\n",
    "W2 = 0.01 * np.random.randn(h,K)\n",
    "b2 = np.zeros((1,K))\n",
    "\n",
    "# Initializing values from hyperparameter\n",
    "reg = 1e-3 # regularization strength\n",
    "\n",
    "#batch SGD using manual backprop\n",
    "\n",
    "#Batch size is equal to number of examples\n",
    "num_examples = X_train.shape[0]\n",
    "\n",
    "#Initial value for the Gradient Descent Parameter\n",
    "step_size = 1e-0 #Also called learning rate\n",
    "\n",
    "d3 = {}\n",
    "d4 = {}\n",
    "\n",
    "iter_list = [0,20,40,60,80,100,200,400,600,800,1000,1200,1400,1600,1800,2000,3000,4000,5000,6000,7000,8000,9000,10000,11000,12000,13000,14000,15000]\n",
    "\n",
    "for j in iter_list:\n",
    "\n",
    "    for i in xrange(j+1):\n",
    "        \n",
    "        # evaluate class scores, [N x K]\n",
    "        hidden_layer = np.maximum(0, np.dot(X_train, W1) + b1) # note, ReLU activation\n",
    "        scores = np.dot(hidden_layer, W2) + b2\n",
    "\n",
    "        # compute the class probabilities\n",
    "        exp_scores = np.exp(scores)\n",
    "        probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # [N x K]\n",
    "\n",
    "        # compute the loss: average cross-entropy loss and regularization\n",
    "        corect_logprobs = -np.log(probs[range(num_examples),y_train])\n",
    "        data_loss = np.sum(corect_logprobs)/num_examples\n",
    "        reg_loss = 0.5*reg*np.sum(W1*W1) + 0.5*reg*np.sum(W2*W2)\n",
    "        loss = data_loss + reg_loss\n",
    "#         if i % 1000 == 0:\n",
    "#             print \"iteration %d: loss %f\" % (i, loss)\n",
    "\n",
    "        # compute the gradient on scores\n",
    "        dscores = probs\n",
    "        dscores[range(num_examples),y_train] -= 1\n",
    "        dscores /= num_examples\n",
    "\n",
    "        # backpropate the gradient to the parameters\n",
    "\n",
    "        # first backprop into parameters W2 and b2\n",
    "        dW2 = np.dot(hidden_layer.T, dscores)\n",
    "        db2 = np.sum(dscores, axis=0, keepdims=True)\n",
    "\n",
    "        # next backprop into hidden layer\n",
    "        dhidden = np.dot(dscores, W2.T)\n",
    "\n",
    "        # backprop the ReLU non-linearity\n",
    "        dhidden[hidden_layer <= 0] = 0\n",
    "\n",
    "        # finally into W1,b1\n",
    "        dW1 = np.dot(X_train.T, dhidden)\n",
    "        db1 = np.sum(dhidden, axis=0, keepdims=True)\n",
    "\n",
    "        # add regularization gradient contribution\n",
    "        dW2 += reg * W2\n",
    "        dW1 += reg * W1\n",
    "\n",
    "        # perform a parameter update\n",
    "        W1 += - step_size * dW1\n",
    "        b1 += - step_size * db1\n",
    "        W2 += - step_size * dW2\n",
    "        b2 += - step_size * db2\n",
    "\n",
    "\n",
    "    # Post-training: evaluate training set accuracy\n",
    "    hidden_layer = np.maximum(0, np.dot(X_train, W1) + b1)\n",
    "    scores = np.dot(hidden_layer, W2) + b2\n",
    "    predicted_class = np.argmax(scores, axis=1)\n",
    "    print \"Number of iterations are {}\".format(i)\n",
    "    print 'train accuracy: %.2f' % (np.mean(predicted_class == y_train))\n",
    "    d3[i] = np.mean((predicted_class == y_train))\n",
    "    \n",
    "    train_accuracy.append(np.mean(predicted_class == y_train))\n",
    "    \n",
    "\n",
    "    # Post-training: evaluate test set accuracy\n",
    "    hidden_layer = np.maximum(0, np.dot(X_test, W1) + b1)\n",
    "    scores = np.dot(hidden_layer, W2) + b2\n",
    "    predicted_class = np.argmax(scores, axis=1)\n",
    "    print \"Number of iterations are {}\".format(i)\n",
    "\n",
    "    print 'test accuracy: %.2f' % (np.mean(predicted_class == y_test))\n",
    "    d4[i] = np.mean((predicted_class == y_test))\n",
    "\n",
    "    test_accuracy.append(np.mean(predicted_class == y_test))\n",
    "\n",
    "print d3\n",
    "print d4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize = (15,5))\n",
    "\n",
    "L=[[key,value] for key,value in d3.items()]\n",
    "L.sort(key= lambda x: x[0])\n",
    "L=np.array(L)\n",
    "\n",
    "# for key,value in d3.items():\n",
    "#     ax[0].plot(key,value,'r',marker = 'o',linestyle = '')\n",
    "ax[0].plot(L[:,0],L[:,1],'r',marker = 'o',linestyle = '-')\n",
    "\n",
    "L=[[key,value] for key,value in d4.items()]\n",
    "L.sort(key= lambda x: x[0])\n",
    "L=np.array(L)\n",
    "\n",
    "\n",
    "# for key,value in d4.items():\n",
    "#     ax[1].plot(key,value,'g',marker = 'o',linestyle = '')\n",
    "ax[1].plot(L[:,0],L[:,1],'g',marker = 'o',linestyle = '-')\n",
    "ax[1].set_ylim([0,1])\n",
    "\n",
    "ax[0].set_xlabel(\"Number of iterations\")\n",
    "ax[0].set_ylabel(\"Training Accuracy\")\n",
    "ax[1].set_xlabel(\"Number of iterations\")\n",
    "ax[1].set_ylabel(\"Test Accuracy\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sensitivity of the model's performance to different regularization parameter values, finding the best regularization parameter using an exhaustive search procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Weights initialization\n",
    "h = 100 # size of hidden layer\n",
    "W1 = 0.01 * np.random.randn(D,h)\n",
    "b1 = np.zeros((1,h))\n",
    "W2 = 0.01 * np.random.randn(h,K)\n",
    "b2 = np.zeros((1,K))\n",
    "\n",
    "# Initializing values from hyperparameter\n",
    "# reg = 1e-3 # regularization strength\n",
    "\n",
    "#batch SGD using manual backprop\n",
    "\n",
    "#Batch size is equal to number of examples\n",
    "num_examples = X_train.shape[0]\n",
    "\n",
    "#Initial value for the Gradient Descent Parameter\n",
    "step_size = 1e-0 #Also called learning rate\n",
    "\n",
    "d5 = {}\n",
    "d6 = {}\n",
    "\n",
    "p = np.arange(0,10,0.1)\n",
    "for j in p:\n",
    "    \n",
    "    for i in xrange(15000):\n",
    "        \n",
    "        # evaluate class scores, [N x K]\n",
    "        hidden_layer = np.maximum(0, np.dot(X_train, W1) + b1) # note, ReLU activation\n",
    "        scores = np.dot(hidden_layer, W2) + b2\n",
    "\n",
    "        # compute the class probabilities\n",
    "        exp_scores = np.exp(scores)\n",
    "        probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # [N x K]\n",
    "\n",
    "        # compute the loss: average cross-entropy loss and regularization\n",
    "        corect_logprobs = -np.log(probs[range(num_examples),y_train])\n",
    "        data_loss = np.sum(corect_logprobs)/num_examples\n",
    "        reg_loss = 0.5*j*np.sum(W1*W1) + 0.5*j*np.sum(W2*W2)\n",
    "        loss = data_loss + reg_loss\n",
    "#         if i % 1000 == 0:\n",
    "#             print \"iteration %d: loss %f\" % (i, loss)\n",
    "\n",
    "        # compute the gradient on scores\n",
    "        dscores = probs\n",
    "        dscores[range(num_examples),y_train] -= 1\n",
    "        dscores /= num_examples\n",
    "\n",
    "        # backpropate the gradient to the parameters\n",
    "\n",
    "        # first backprop into parameters W2 and b2\n",
    "        dW2 = np.dot(hidden_layer.T, dscores)\n",
    "        db2 = np.sum(dscores, axis=0, keepdims=True)\n",
    "\n",
    "        # next backprop into hidden layer\n",
    "        dhidden = np.dot(dscores, W2.T)\n",
    "\n",
    "        # backprop the ReLU non-linearity\n",
    "        dhidden[hidden_layer <= 0] = 0\n",
    "\n",
    "        # finally into W1,b1\n",
    "        dW1 = np.dot(X_train.T, dhidden)\n",
    "        db1 = np.sum(dhidden, axis=0, keepdims=True)\n",
    "\n",
    "        # add regularization gradient contribution\n",
    "        dW2 += j * W2\n",
    "        dW1 += j * W1\n",
    "\n",
    "        # perform a parameter update\n",
    "        W1 += - step_size * dW1\n",
    "        b1 += - step_size * db1\n",
    "        W2 += - step_size * dW2\n",
    "        b2 += - step_size * db2\n",
    "\n",
    "\n",
    "    # Post-training: evaluate training set accuracy\n",
    "    hidden_layer = np.maximum(0, np.dot(X_train, W1) + b1)\n",
    "    scores = np.dot(hidden_layer, W2) + b2\n",
    "    predicted_class = np.argmax(scores, axis=1)\n",
    "    print \"Regularization parameter is {}\".format(j)\n",
    "    print 'train accuracy: %.2f' % (np.mean(predicted_class == y_train))\n",
    "    d5[j] = np.mean((predicted_class == y_train))\n",
    "    \n",
    "    train_accuracy.append(np.mean(predicted_class == y_train))\n",
    "    \n",
    "\n",
    "    # Post-training: evaluate test set accuracy\n",
    "    hidden_layer = np.maximum(0, np.dot(X_test, W1) + b1)\n",
    "    scores = np.dot(hidden_layer, W2) + b2\n",
    "    predicted_class = np.argmax(scores, axis=1)\n",
    "    print \"Regularization parameter is {}\".format(j)\n",
    "\n",
    "    print 'test accuracy: %.2f' % (np.mean(predicted_class == y_test))\n",
    "    d6[j] = np.mean((predicted_class == y_test))\n",
    "\n",
    "    test_accuracy.append(np.mean(predicted_class == y_test))\n",
    "\n",
    "print np.mean(d5.values())\n",
    "print np.mean(d6.values())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# range of the regularisation parameter is considered between 0 t0 10 with increments of 0.1\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize = (15,5))\n",
    "\n",
    "\n",
    "for key,value in d5.items():\n",
    "    ax[0].plot(key,value,'r',marker = 'o',linestyle = '')\n",
    "\n",
    "for key,value in d6.items():\n",
    "    ax[1].plot(key,value,'g',marker = 'o',linestyle = '')\n",
    "\n",
    "ax[0].set_xlabel(\"Regularization parameter\")\n",
    "ax[0].set_ylabel(\"Training Accuracy\")\n",
    "ax[1].set_xlabel(\"Regularization parameter\")\n",
    "ax[1].set_ylabel(\"Test Accuracy\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what are my results if I don't multiply the regularization loss with 0.5 and the range is from 0 to 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Weights initialization\n",
    "h = 100 # size of hidden layer\n",
    "W1 = 0.01 * np.random.randn(D,h)\n",
    "b1 = np.zeros((1,h))\n",
    "W2 = 0.01 * np.random.randn(h,K)\n",
    "b2 = np.zeros((1,K))\n",
    "\n",
    "# Initializing values from hyperparameter\n",
    "# reg = 1e-3 # regularization strength\n",
    "\n",
    "#batch SGD using manual backprop\n",
    "\n",
    "#Batch size is equal to number of examples\n",
    "num_examples = X_train.shape[0]\n",
    "\n",
    "#Initial value for the Gradient Descent Parameter\n",
    "step_size = 1e-0 #Also called learning rate\n",
    "\n",
    "d5 = {}\n",
    "d6 = {}\n",
    "\n",
    "p = np.arange(0,10,0.1)\n",
    "for j in p:\n",
    "    \n",
    "    for i in xrange(15000):\n",
    "        \n",
    "        # evaluate class scores, [N x K]\n",
    "        hidden_layer = np.maximum(0, np.dot(X_train, W1) + b1) # note, ReLU activation\n",
    "        scores = np.dot(hidden_layer, W2) + b2\n",
    "\n",
    "        # compute the class probabilities\n",
    "        exp_scores = np.exp(scores)\n",
    "        probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # [N x K]\n",
    "\n",
    "        # compute the loss: average cross-entropy loss and regularization\n",
    "        corect_logprobs = -np.log(probs[range(num_examples),y_train])\n",
    "        data_loss = np.sum(corect_logprobs)/num_examples\n",
    "        reg_loss = j*np.sum(W1*W1) + j*np.sum(W2*W2)\n",
    "        loss = data_loss + reg_loss\n",
    "#         if i % 1000 == 0:\n",
    "#             print \"iteration %d: loss %f\" % (i, loss)\n",
    "\n",
    "        # compute the gradient on scores\n",
    "        dscores = probs\n",
    "        dscores[range(num_examples),y_train] -= 1\n",
    "        dscores /= num_examples\n",
    "\n",
    "        # backpropate the gradient to the parameters\n",
    "\n",
    "        # first backprop into parameters W2 and b2\n",
    "        dW2 = np.dot(hidden_layer.T, dscores)\n",
    "        db2 = np.sum(dscores, axis=0, keepdims=True)\n",
    "\n",
    "        # next backprop into hidden layer\n",
    "        dhidden = np.dot(dscores, W2.T)\n",
    "\n",
    "        # backprop the ReLU non-linearity\n",
    "        dhidden[hidden_layer <= 0] = 0\n",
    "\n",
    "        # finally into W1,b1\n",
    "        dW1 = np.dot(X_train.T, dhidden)\n",
    "        db1 = np.sum(dhidden, axis=0, keepdims=True)\n",
    "\n",
    "        # add regularization gradient contribution\n",
    "        dW2 += j * W2\n",
    "        dW1 += j * W1\n",
    "\n",
    "        # perform a parameter update\n",
    "        W1 += - step_size * dW1\n",
    "        b1 += - step_size * db1\n",
    "        W2 += - step_size * dW2\n",
    "        b2 += - step_size * db2\n",
    "\n",
    "\n",
    "    # Post-training: evaluate training set accuracy\n",
    "    hidden_layer = np.maximum(0, np.dot(X_train, W1) + b1)\n",
    "    scores = np.dot(hidden_layer, W2) + b2\n",
    "    predicted_class = np.argmax(scores, axis=1)\n",
    "    print \"Regularization parameter is {}\".format(j)\n",
    "    print 'train accuracy: %.2f' % (np.mean(predicted_class == y_train))\n",
    "    d5[j] = np.mean((predicted_class == y_train))\n",
    "    \n",
    "    train_accuracy.append(np.mean(predicted_class == y_train))\n",
    "    \n",
    "\n",
    "    # Post-training: evaluate test set accuracy\n",
    "    hidden_layer = np.maximum(0, np.dot(X_test, W1) + b1)\n",
    "    scores = np.dot(hidden_layer, W2) + b2\n",
    "    predicted_class = np.argmax(scores, axis=1)\n",
    "    print \"Regularization parameter is {}\".format(j)\n",
    "\n",
    "    print 'test accuracy: %.2f' % (np.mean(predicted_class == y_test))\n",
    "    d6[j] = np.mean((predicted_class == y_test))\n",
    "\n",
    "    test_accuracy.append(np.mean(predicted_class == y_test))\n",
    "\n",
    "print np.mean(d5.values())\n",
    "print np.mean(d6.values())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# range of the regularisation parameter is considered between 0 t0 1 with increments of 0.1 and the regularization loss is \n",
    "#not multiplied by 0.5\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize = (15,5))\n",
    "\n",
    "\n",
    "for key,value in d5.items():\n",
    "    ax[0].plot(key,value,'r',marker = 'o',linestyle = '')\n",
    "\n",
    "for key,value in d6.items():\n",
    "    ax[1].plot(key,value,'g',marker = 'o',linestyle = '')\n",
    "\n",
    "ax[0].set_xlabel(\"Regularization parameter\")\n",
    "ax[0].set_ylabel(\"Training Accuracy\")\n",
    "ax[1].set_xlabel(\"Regularization parameter\")\n",
    "ax[1].set_ylabel(\"Test Accuracy\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Weights initialization\n",
    "h = 100 # size of hidden layer\n",
    "W1 = 0.01 * np.random.randn(D,h)\n",
    "b1 = np.zeros((1,h))\n",
    "W2 = 0.01 * np.random.randn(h,K)\n",
    "b2 = np.zeros((1,K))\n",
    "\n",
    "# Initializing values from hyperparameter\n",
    "# reg = 1e-3 # regularization strength\n",
    "\n",
    "#batch SGD using manual backprop\n",
    "\n",
    "#Batch size is equal to number of examples\n",
    "num_examples = X_train.shape[0]\n",
    "\n",
    "#Initial value for the Gradient Descent Parameter\n",
    "step_size = 1e-0 #Also called learning rate\n",
    "\n",
    "d5 = {}\n",
    "d6 = {}\n",
    "\n",
    "p = np.arange(1e-4,1,1e-2)\n",
    "for j in p:\n",
    "    \n",
    "    for i in xrange(15000):\n",
    "        \n",
    "        # evaluate class scores, [N x K]\n",
    "        hidden_layer = np.maximum(0, np.dot(X_train, W1) + b1) # note, ReLU activation\n",
    "        scores = np.dot(hidden_layer, W2) + b2\n",
    "\n",
    "        # compute the class probabilities\n",
    "        exp_scores = np.exp(scores)\n",
    "        probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # [N x K]\n",
    "\n",
    "        # compute the loss: average cross-entropy loss and regularization\n",
    "        corect_logprobs = -np.log(probs[range(num_examples),y_train])\n",
    "        data_loss = np.sum(corect_logprobs)/num_examples\n",
    "        reg_loss = j*np.sum(W1*W1) + j*np.sum(W2*W2)\n",
    "        loss = data_loss + reg_loss\n",
    "#         if i % 1000 == 0:\n",
    "#             print \"iteration %d: loss %f\" % (i, loss)\n",
    "\n",
    "        # compute the gradient on scores\n",
    "        dscores = probs\n",
    "        dscores[range(num_examples),y_train] -= 1\n",
    "        dscores /= num_examples\n",
    "\n",
    "        # backpropate the gradient to the parameters\n",
    "\n",
    "        # first backprop into parameters W2 and b2\n",
    "        dW2 = np.dot(hidden_layer.T, dscores)\n",
    "        db2 = np.sum(dscores, axis=0, keepdims=True)\n",
    "\n",
    "        # next backprop into hidden layer\n",
    "        dhidden = np.dot(dscores, W2.T)\n",
    "\n",
    "        # backprop the ReLU non-linearity\n",
    "        dhidden[hidden_layer <= 0] = 0\n",
    "\n",
    "        # finally into W1,b1\n",
    "        dW1 = np.dot(X_train.T, dhidden)\n",
    "        db1 = np.sum(dhidden, axis=0, keepdims=True)\n",
    "\n",
    "        # add regularization gradient contribution\n",
    "        dW2 += j * W2\n",
    "        dW1 += j * W1\n",
    "\n",
    "        # perform a parameter update\n",
    "        W1 += - step_size * dW1\n",
    "        b1 += - step_size * db1\n",
    "        W2 += - step_size * dW2\n",
    "        b2 += - step_size * db2\n",
    "\n",
    "\n",
    "    # Post-training: evaluate training set accuracy\n",
    "    hidden_layer = np.maximum(0, np.dot(X_train, W1) + b1)\n",
    "    scores = np.dot(hidden_layer, W2) + b2\n",
    "    predicted_class = np.argmax(scores, axis=1)\n",
    "    print \"Regularization parameter is {}\".format(j)\n",
    "    print 'train accuracy: %.2f' % (np.mean(predicted_class == y_train))\n",
    "    d5[j] = np.mean((predicted_class == y_train))\n",
    "    \n",
    "    train_accuracy.append(np.mean(predicted_class == y_train))\n",
    "    \n",
    "\n",
    "    # Post-training: evaluate test set accuracy\n",
    "    hidden_layer = np.maximum(0, np.dot(X_test, W1) + b1)\n",
    "    scores = np.dot(hidden_layer, W2) + b2\n",
    "    predicted_class = np.argmax(scores, axis=1)\n",
    "    print \"Regularization parameter is {}\".format(j)\n",
    "\n",
    "    print 'test accuracy: %.2f' % (np.mean(predicted_class == y_test))\n",
    "    d6[j] = np.mean((predicted_class == y_test))\n",
    "\n",
    "    test_accuracy.append(np.mean(predicted_class == y_test))\n",
    "\n",
    "print np.mean(d5.values())\n",
    "print np.mean(d6.values())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# range of the regularisation parameter is considered between 0 t0 10 with increments of 0.1 and the regularization loss is \n",
    "#multiplied by 0.5\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize = (15,5))\n",
    "\n",
    "L=[[key,value] for key,value in d5.items()]\n",
    "L.sort(key= lambda x: x[0])\n",
    "L=np.array(L)\n",
    "# for key,value in d5.items():\n",
    "ax[0].semilogx(L[:,0],L[:,1],'r',marker = 'o',linestyle = '-')\n",
    "\n",
    "\n",
    "L=[[key,value] for key,value in d6.items()]\n",
    "L.sort(key= lambda x: x[0])\n",
    "L=np.array(L)\n",
    "\n",
    "# for key,value in d6.items():\n",
    "ax[1].semilogx(L[:,0],L[:,1],'g',marker = 'o',linestyle = '-')\n",
    "\n",
    "ax[0].set_xlabel(\"Regularization parameter\")\n",
    "ax[0].set_ylabel(\"Training Accuracy\")\n",
    "ax[1].set_xlabel(\"Regularization parameter\")\n",
    "ax[1].set_ylabel(\"Test Accuracy\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sensitivity of the model's performance with respect to a different test train split (50%:50%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.5, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feedforward neural net model\n",
    "\n",
    "\n",
    "# Weights initialization\n",
    "h = 100 # size of hidden layer\n",
    "W1 = 0.01 * np.random.randn(D,h)\n",
    "b1 = np.zeros((1,h))\n",
    "W2 = 0.01 * np.random.randn(h,K)\n",
    "b2 = np.zeros((1,K))\n",
    "\n",
    "# Initializing values from hyperparameter\n",
    "reg = 1e-3 # regularization strength\n",
    "\n",
    "#batch SGD using manual backprop\n",
    "\n",
    "#Batch size is equal to number of examples\n",
    "num_examples = X_train.shape[0]\n",
    "\n",
    "#Initial value for the Gradient Descent Parameter\n",
    "step_size = 1e-0 #Also called learning rate\n",
    "\n",
    "# gradient descent loop\n",
    "for i in xrange(10000):\n",
    "    # evaluate class scores, [N x K]\n",
    "    hidden_layer = np.maximum(0, np.dot(X_train, W1) + b1) # note, ReLU activation\n",
    "    scores = np.dot(hidden_layer, W2) + b2\n",
    "    \n",
    "    # compute the class probabilities\n",
    "    exp_scores = np.exp(scores)\n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # [N x K]\n",
    "    \n",
    "    # compute the loss: average cross-entropy loss and regularization\n",
    "    corect_logprobs = -np.log(probs[range(num_examples),y_train])\n",
    "    data_loss = np.sum(corect_logprobs)/num_examples\n",
    "    reg_loss = 0.5*reg*np.sum(W1*W1) + 0.5*reg*np.sum(W2*W2)\n",
    "    loss = data_loss + reg_loss\n",
    "    if i % 1000 == 0:\n",
    "        print \"iteration %d: loss %f\" % (i, loss)\n",
    "  \n",
    "    # compute the gradient on scores\n",
    "    dscores = probs\n",
    "    dscores[range(num_examples),y_train] -= 1\n",
    "    dscores /= num_examples\n",
    "  \n",
    "    # backpropate the gradient to the parameters\n",
    "    \n",
    "    # first backprop into parameters W2 and b2\n",
    "    dW2 = np.dot(hidden_layer.T, dscores)\n",
    "    db2 = np.sum(dscores, axis=0, keepdims=True)\n",
    "    \n",
    "    # next backprop into hidden layer\n",
    "    dhidden = np.dot(dscores, W2.T)\n",
    "    \n",
    "    # backprop the ReLU non-linearity\n",
    "    dhidden[hidden_layer <= 0] = 0\n",
    "    \n",
    "    # finally into W1,b1\n",
    "    dW1 = np.dot(X_train.T, dhidden)\n",
    "    db1 = np.sum(dhidden, axis=0, keepdims=True)\n",
    "  \n",
    "    # add regularization gradient contribution\n",
    "    dW2 += reg * W2\n",
    "    dW1 += reg * W1\n",
    "  \n",
    "    # perform a parameter update\n",
    "    W1 += -step_size * dW1\n",
    "    b1 += -step_size * db1\n",
    "    W2 += -step_size * dW2\n",
    "    b2 += -step_size * db2\n",
    "\n",
    "    \n",
    "# Post-training: evaluate t set accuracy\n",
    "hidden_layer = np.maximum(0, np.dot(X_train, W1) + b1)\n",
    "scores = np.dot(hidden_layer, W2) + b2\n",
    "predicted_class = np.argmax(scores, axis=1)\n",
    "print 'train accuracy: %.2f' % (np.mean(predicted_class == y_train))\n",
    "\n",
    "# Post-training: evaluate test set accuracy\n",
    "hidden_layer = np.maximum(0, np.dot(X_test, W1) + b1)\n",
    "scores = np.dot(hidden_layer, W2) + b2\n",
    "predicted_class = np.argmax(scores, axis=1)\n",
    "print 'test accuracy: %.2f' % (np.mean(predicted_class == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## what happens when the number of hidden units chosen is much smaller. Similarly, what happens when the number of hidden units chosen is much higher?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feedforward neural net model\n",
    "\n",
    "\n",
    "# Weights initialization\n",
    "h = [10,50,100,200,500,1000]# size of hidden layer\n",
    "d7 = {}\n",
    "d8 = {}\n",
    "for j in h:\n",
    "    print \"Number of hidden neurons is {}\".format(j)\n",
    "    W1 = 0.01 * np.random.randn(D,j)\n",
    "    b1 = np.zeros((1,j))\n",
    "    W2 = 0.01 * np.random.randn(j,K)\n",
    "    b2 = np.zeros((1,K))\n",
    "\n",
    "    # Initializing values from hyperparameter\n",
    "    reg = 1e-3 # regularization strength\n",
    "\n",
    "    #batch SGD using manual backprop\n",
    "\n",
    "    #Batch size is equal to number of examples\n",
    "    num_examples = X_train.shape[0]\n",
    "\n",
    "    #Initial value for the Gradient Descent Parameter\n",
    "    step_size = 1e-0 #Also called learning rate\n",
    "\n",
    "    # gradient descent loop\n",
    "    for i in xrange(10000):\n",
    "        # evaluate class scores, [N x K]\n",
    "        hidden_layer = np.maximum(0, np.dot(X_train, W1) + b1) # note, ReLU activation\n",
    "        scores = np.dot(hidden_layer, W2) + b2\n",
    "\n",
    "        # compute the class probabilities\n",
    "        exp_scores = np.exp(scores)\n",
    "        probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # [N x K]\n",
    "\n",
    "        # compute the loss: average cross-entropy loss and regularization\n",
    "        corect_logprobs = -np.log(probs[range(num_examples),y_train])\n",
    "        data_loss = np.sum(corect_logprobs)/num_examples\n",
    "        reg_loss = 0.5*reg*np.sum(W1*W1) + 0.5*reg*np.sum(W2*W2)\n",
    "        loss = data_loss + reg_loss\n",
    "        if i % 1000 == 0:\n",
    "            print \"iteration %d: loss %f\" % (i, loss)\n",
    "\n",
    "        # compute the gradient on scores\n",
    "        dscores = probs\n",
    "        dscores[range(num_examples),y_train] -= 1\n",
    "        dscores /= num_examples\n",
    "\n",
    "        # backpropate the gradient to the parameters\n",
    "\n",
    "        # first backprop into parameters W2 and b2\n",
    "        dW2 = np.dot(hidden_layer.T, dscores)\n",
    "        db2 = np.sum(dscores, axis=0, keepdims=True)\n",
    "\n",
    "        # next backprop into hidden layer\n",
    "        dhidden = np.dot(dscores, W2.T)\n",
    "\n",
    "        # backprop the ReLU non-linearity\n",
    "        dhidden[hidden_layer <= 0] = 0\n",
    "\n",
    "        # finally into W1,b1\n",
    "        dW1 = np.dot(X_train.T, dhidden)\n",
    "        db1 = np.sum(dhidden, axis=0, keepdims=True)\n",
    "\n",
    "        # add regularization gradient contribution\n",
    "        dW2 += reg * W2\n",
    "        dW1 += reg * W1\n",
    "\n",
    "        # perform a parameter update\n",
    "        W1 += -step_size * dW1\n",
    "        b1 += -step_size * db1\n",
    "        W2 += -step_size * dW2\n",
    "        b2 += -step_size * db2\n",
    "\n",
    "\n",
    "    # Post-training: evaluate t set accuracy\n",
    "    hidden_layer = np.maximum(0, np.dot(X_train, W1) + b1)\n",
    "    scores = np.dot(hidden_layer, W2) + b2\n",
    "    predicted_class = np.argmax(scores, axis=1)\n",
    "    print 'train accuracy: %.2f' % (np.mean(predicted_class == y_train))\n",
    "    d7[j] = np.mean((predicted_class == y_train))\n",
    "\n",
    "\n",
    "    # Post-training: evaluate test set accuracy\n",
    "    hidden_layer = np.maximum(0, np.dot(X_test, W1) + b1)\n",
    "    scores = np.dot(hidden_layer, W2) + b2\n",
    "    predicted_class = np.argmax(scores, axis=1)\n",
    "    print 'test accuracy: %.2f' % (np.mean(predicted_class == y_test))\n",
    "    d8[j] = np.mean((predicted_class == y_test))\n",
    "    \n",
    "print d7\n",
    "print d8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# range of the regularisation parameter is considered between 0 t0 10 with increments of 0.1 and the regularization loss is \n",
    "#multiplied by 0.5\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize = (15,5))\n",
    "\n",
    "L=[[key,value] for key,value in d7.items()]\n",
    "L.sort(key= lambda x: x[0])\n",
    "L=np.array(L)\n",
    "# for key,value in d5.items():\n",
    "ax[0].semilogx(L[:,0],L[:,1],'r',marker = 'o',linestyle = '-')\n",
    "\n",
    "\n",
    "L=[[key,value] for key,value in d8.items()]\n",
    "L.sort(key= lambda x: x[0])\n",
    "L=np.array(L)\n",
    "\n",
    "# for key,value in d6.items():\n",
    "ax[1].semilogx(L[:,0],L[:,1],'g',marker = 'o',linestyle = '-')\n",
    "\n",
    "ax[0].set_xlabel(\"Size of Hidden Layer\")\n",
    "ax[0].set_ylabel(\"Training Accuracy\")\n",
    "ax[1].set_xlabel(\"Size of Hidden Layer\")\n",
    "ax[1].set_ylabel(\"Test Accuracy\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
